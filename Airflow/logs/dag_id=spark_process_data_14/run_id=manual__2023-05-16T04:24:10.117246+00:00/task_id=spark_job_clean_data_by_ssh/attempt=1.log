[2023-05-16T04:24:12.371+0000] {warnings.py:110} WARNING - /usr/local/lib/python3.7/site-packages/***/models/taskinstance.py:871: SAWarning: TypeDecorator ExecutorConfigType() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)
  ti: TaskInstance | None = qry.with_for_update().one_or_none()

[2023-05-16T04:24:12.462+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: spark_process_data_14.spark_job_clean_data_by_ssh manual__2023-05-16T04:24:10.117246+00:00 [queued]>
[2023-05-16T04:24:12.516+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: spark_process_data_14.spark_job_clean_data_by_ssh manual__2023-05-16T04:24:10.117246+00:00 [queued]>
[2023-05-16T04:24:12.519+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-16T04:24:12.520+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2023-05-16T04:24:12.521+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-16T04:24:12.609+0000] {taskinstance.py:1383} INFO - Executing <Task(SSHOperator): spark_job_clean_data_by_ssh> on 2023-05-16 04:24:10.117246+00:00
[2023-05-16T04:24:12.626+0000] {standard_task_runner.py:54} INFO - Started process 181 to run task
[2023-05-16T04:24:12.641+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'spark_process_data_14', 'spark_job_clean_data_by_ssh', 'manual__2023-05-16T04:24:10.117246+00:00', '--job-id', '3809', '--raw', '--subdir', 'DAGS_FOLDER/spark_process_scheduler.py', '--cfg-path', '/tmp/tmpfo0aujxz']
[2023-05-16T04:24:12.643+0000] {standard_task_runner.py:83} INFO - Job 3809: Subtask spark_job_clean_data_by_ssh
[2023-05-16T04:24:12.647+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/spark_process_scheduler.py
[2023-05-16T04:24:12.834+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 3809 for task spark_job_clean_data_by_ssh (Task spark_job_clean_data_by_ssh not found; 181)
[2023-05-16T04:24:12.900+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2023-05-16T04:24:13.063+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
